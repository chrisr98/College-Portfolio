{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loadhw4' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-afe1aa4d8880>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# to the List below. If you need to do so, you can create paths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# in a platform-indepenent manner using \"os.path.join(...)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0m_cd_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloadhw4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_dir_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_cd_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# add other paths here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_dir_\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loadhw4' is not defined"
     ]
    }
   ],
   "source": [
    "# SYSTEM IMPORTS\n",
    "from typing import Callable, List, Tuple, Type, Sequence\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "# the following code snippet is to make sure that when we import\n",
    "# python modules that are not in the default python installation,\n",
    "# the python interpreter knows where to find the files. This is\n",
    "# exactly like the $PATH environment variable present in every\n",
    "# operating system.\n",
    "\n",
    "# I have assumed that you have kept the \"loadhw4.py\" file in the\n",
    "# same directory as this script, otherwise you will have to add\n",
    "# the path (perferrably relative to the path to this script)\n",
    "# to the List below. If you need to do so, you can create paths\n",
    "# in a platform-indepenent manner using \"os.path.join(...)\"\n",
    "_cd_: str = os.path.abspath(os.path.dirname(__file__))\n",
    "for _dir_ in [_cd_]: # add other paths here\n",
    "    if _dir_ not in sys.path:\n",
    "        sys.path.append(_dir_)\n",
    "del _cd_\n",
    "\n",
    "\n",
    "# PYTHON PROJECT IMPORTS\n",
    "from loadhw4 import loadhw4\n",
    "\n",
    "\n",
    "# numerical gradient checking...this is how we check whether\n",
    "# our backpropogation works or not. What we do is compute the\n",
    "# numerical partial derivative with respect to each learnable\n",
    "# parameter. A numerical derivative can be computed using:\n",
    "#       df/dx = (f(x+e) - f(x-e))/(2*e)\n",
    "# if we set e to be really small, then we can get a good approx\n",
    "# of the gradient. We can compare the symbolic gradients\n",
    "# versus the numerical gradients, and hope they are super close\n",
    "def grad_check(X: np.ndarray, Y_gt: np.ndarray, m: object,\n",
    "               error_func: Type[object], epsilon: float = 1e-9,\n",
    "               delta: float = 1e-6) -> None:\n",
    "    params: List[np.ndarray] = m.parameters()\n",
    "\n",
    "    sym_grads: List[np.ndarray] = m.backward(X, error_func.backward(m.forward(X), Y_gt))\n",
    "    num_grads: List[np.ndarray] = [np.zeros_like(P) for P in params]\n",
    "\n",
    "    for P, num_G in zip(params, num_grads):\n",
    "        for index, p_i in np.ndenumerate(P):\n",
    "            P[index] += epsilon\n",
    "            num_G[index] += error_func.forward(m.forward(X), Y_gt)\n",
    "\n",
    "            P -= 2*epsilon\n",
    "            num_G[index] -= error_func.forward(m.forward(X), Y_gt)\n",
    "\n",
    "            P[index] = p_i\n",
    "            num_G[index] /= 2*epsilon\n",
    "\n",
    "    ratios: np.ndarray = np.array([np.linalg.norm(SG-NG)/\n",
    "                                   np.linalg.norm(SG+NG)\n",
    "                                   for SG, NG in zip(sym_grads, num_grads)], dtype=float)\n",
    "    if np.sum(ratios > delta) > 0:\n",
    "        raise RuntimeError(\"ERROR: failed grad check. delta: [%s], ratios: %s\" % delta, ratios)\n",
    "\n",
    "\n",
    "# our error function. This is given to you in a separate file\n",
    "# but I figured I would include it here.\n",
    "class BCE(object):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(Y_hat: np.ndarray, Y_gt: np.ndarray) -> float:\n",
    "        assert(Y_hat.shape == Y_gt.shape)\n",
    "        return np.sum(-np.log(Y_hat[Y_gt==0])) + np.sum(-np.log(1-Y_hat[Y_gt!=0]))\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(Y_hat: np.ndarray, Y_gt: np.ndarray) -> np.ndarray:\n",
    "        assert(Y_hat.shape == Y_gt.shape)\n",
    "        assert(len(Y_hat.shape) == 1 or (len(Y_hat.shape == 2) and Y_hat.shape[-1] == 1))\n",
    "        dE_dYhat = np.zeros(Y_hat.shape)\n",
    "        dE_dYhat[Y_gt==0] = -1.0/(Y_hat[Y_gt==0])\n",
    "        dE_dYhat[Y_gt!=0] = 1.0/(1-Y_hat[Y_gt!=0])\n",
    "        return dE_dYhat\n",
    "\n",
    "\n",
    "# our sigmoid function. I chose to separate this out because\n",
    "# I prefer a more modular design\n",
    "class Sigmoid(object):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(X: np.ndarray) -> np.ndarray:\n",
    "        return 1/(1+np.exp(-X))\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(X: np.ndarray, de_dSigmoid) -> np.ndarray:\n",
    "        print(X)\n",
    "        # TODO: compute de/dX = de/dSigmoid * dSigmoid/dX\n",
    "        ...\n",
    "\n",
    "\n",
    "# a helpful utility function to abstract away making minibatches\n",
    "def make_minibatches(X: np.ndarray, Y: np.ndarray, minibatch_size: int) -> Sequence[Tuple[np.ndarray, np.ndarray]]:\n",
    "    # sanity check\n",
    "    assert(X.shape[0] == Y.shape[0]) # should have same number of examples\n",
    "    assert(minibatch_size > 0)\n",
    "    assert(minibatch_size <= X.shape[0])\n",
    "    if minibatch_size == X.shape[0]:\n",
    "        yield X, Y\n",
    "\n",
    "    else:\n",
    "        # randomly shuffle the data\n",
    "        minibatch_ids: np.ndarray = np.random.randint(low=0, high=minibatch_size,\n",
    "                                                      size=np.ceil(X.shape[0] / minibatch_size))\n",
    "        for i in minibatch_ids:\n",
    "            yield X[minibatch_ids==i,:], Y[minibatch_ids==i,:]\n",
    "\n",
    "\n",
    "# FINALLY, our logistic regression class (whew!)\n",
    "class LR(object):\n",
    "    def __init__(self, num_features: int) -> None:\n",
    "        self.W: np.ndarray = np.random.randn(num_features, 1)\n",
    "        self.b: np.ndarray = np.random.randn(1,1)\n",
    "\n",
    "    # used by the grad_check function\n",
    "    def parameters(self) -> List[np.ndarray]:\n",
    "        return [self.W, self.b]\n",
    "\n",
    "    def forward(self, X: np.ndarray) -> np.ndarray:\n",
    "        return Sigmoid.forward(np.dot(X, self.W) + self.b)\n",
    "\n",
    "    def classify(self, X: np.ndarray) -> np.ndarray:\n",
    "        # need Pr(c_0|x) = 1 maps to class 0\n",
    "        # and  Pr(c_0|x) = 0 maps to class 1\n",
    "        return np.abs(1-np.round(self.forward(X)))\n",
    "\n",
    "    def backward(self, X: np.ndarray, de_dYhat: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        de_dW: np.ndarray = np.zeros_like(self.W)\n",
    "        de_db: np.ndarray = np.zeros_like(self.b)\n",
    "\n",
    "        # TODO: compute de/dW, de/db\n",
    "\n",
    "        return de_dW, de_db\n",
    "\n",
    "    def SGD(self, X: np.ndarray, Y: np.ndarray, eta: float,\n",
    "            minibatch_size: int = None,\n",
    "            check_grads: bool = False) -> None:\n",
    "        # perform one update of SGD....a full pass through the data\n",
    "        # although if minibatch_size is None, we will just perform\n",
    "        # vanilla gradient descent\n",
    "        if minibatch_size is None:\n",
    "            minibatch_size = X.shape[0]\n",
    "\n",
    "        for X_batch, Y_batch in make_minibatches(X, Y, minibatch_size):\n",
    "            if check_grads:\n",
    "                grad_check(X_batch, Y_batch, self, BCE)\n",
    "\n",
    "            de_dW, de_db = self.backward(X_batch, BCE.backward(self.forward(X_batch), Y_batch))\n",
    "\n",
    "            self.W = self.W - eta*de_dW\n",
    "            self.b = self.b - eta*de_db\n",
    "\n",
    "    def train(self, X: np.ndarray, Y_gt: np.ndarray, eta: float,\n",
    "              minibatch_size: int = None,\n",
    "              check_grads: bool = False,\n",
    "              max_epochs: int = 1e6,\n",
    "              val_func: Callable[[\"LR\"], None] = None) -> None:\n",
    "        # TODO: train on the training data using SGD until convergence\n",
    "        # or max_epochs is reached. If val_func is not None,\n",
    "        # val_func should be called after every epoch. It takes\n",
    "        # the model instance as a parameter and returns nothing.\n",
    "        ...\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    # step 1) load in the data\n",
    "    (X_train, Y_train), (X_val, Y_val), (X_test, Y_test) = loadhw4()\n",
    "\n",
    "    # step 2) convert ground truth data from the class label ([0,1]) into Pr(c_0 | x)\n",
    "    def convert_cls_to_pr(Y_gt_classes: np.ndarray) -> np.ndarray:\n",
    "        Y_gt_pr: np.ndarray = np.zeros_like(Y_gt_classes)\n",
    "\n",
    "        # if the class is 0, then Pr(c_0|x) == 1 and vice versa\n",
    "        Y_gt_pr[Y_gt_classes == 0] = 1\n",
    "        Y_gt_pr[Y_gt_classes == 1] = 0\n",
    "        return Y_gt_pr\n",
    "\n",
    "    Y_train = convert_cls_to_pr(Y_train)\n",
    "    Y_val = convert_cls_to_pr(Y_val)\n",
    "    Y_test = convert_cls_to_pr(Y_test)\n",
    "\n",
    "    # step 3) train your model on the data\n",
    "    def convert_pr_to_cls(Y_gt_pr: np.ndarray) -> np.ndarray:\n",
    "        return np.abs(1-np.round(Y_gt_pr))\n",
    "\n",
    "    # feel free to use this function to evaluate your model on\n",
    "    # the validation data. This function measures accuracy, but\n",
    "    # this may not be the best metric (check data balance!!!!)\n",
    "    metrics: List[float] = list()\n",
    "    params_per_epoch: List[Tuple[np.ndarray]] = list()\n",
    "    def eval_acc(m: LR) -> None:\n",
    "        Y_hat_cls: np.ndarray = m.classify(X_val)\n",
    "        Y_gt_cls: np.ndarray = convert_pr_to_cls(Y_val)\n",
    "\n",
    "        # accuracy\n",
    "        acc:float = np.sum(Y_hat_cls == Y_gt_cls) / Y_gt_cls.shape[0]\n",
    "        metrics.append(acc)\n",
    "        params_per_epoch.append((P.copy() for P in m.parameters()))\n",
    "\n",
    "    # TODO: train and evaluate your model on the val data after every epoch\n",
    "\n",
    "    # step 4) look at your metric results! Use the metrics array\n",
    "    #         to pick the best model\n",
    "    plt.plot(np.arange(len(metrics)), metrics)\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"metric\")\n",
    "    plt.show()\n",
    "\n",
    "    # step 5) test your model on the testing data\n",
    "    Y_hat_cls: np.ndarray = m.classify(X_test)\n",
    "    Y_gt_cls: np.ndarray = convert_pr_to_cls(Y_test)\n",
    "\n",
    "    # step 6) how well did you do? Use some metric\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exercise 1 part 1\n",
      "\n",
      "1e-06\n",
      "Original X:  [2.12553301]\n",
      "X value found:  [nan]\n",
      "Number of iterations before convergence:  1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:42: RuntimeWarning: overflow encountered in power\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:42: RuntimeWarning: overflow encountered in square\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:47: RuntimeWarning: overflow encountered in power\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:47: RuntimeWarning: overflow encountered in square\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:42: RuntimeWarning: invalid value encountered in add\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:47: RuntimeWarning: invalid value encountered in add\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exercise 1 part 2\n",
      "\n",
      "1e-06\n",
      "Original X:  [2.58048674]\n",
      "X value found:  [1.00000151]\n",
      "Number of iterations before convergence:  29\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SYSTEM IMPORTS\n",
    "from typing import Callable, List, Tuple, Type, Sequence\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def main()->np.random.seed(1):\n",
    "    # Picking a random number\n",
    "    x_t:np_ndarray = np.array([np.random.uniform(low=1.5,high =3) for i in range(1)], dtype = float)\n",
    "    \n",
    "    max_iter = 1000\n",
    "    converged = False\n",
    "    t = 0;\n",
    "    delta = 1e-6\n",
    "    print(delta)\n",
    "    f_of_x: List(float) = [f(x_t)]\n",
    "    print(\"Original X: \",x_t)\n",
    "    \n",
    "    while not converged and t < max_iter:\n",
    "        eta: float = 0.001\n",
    "        x_t_plus_1: np.ndarray = x_t - eta*df_dx(x_t)\n",
    "        if(np.linalg.norm(x_t_plus_1 - x_t, ord=2) <= delta):\n",
    "            converged  = True\n",
    "        t+=1\n",
    "        x_t = x_t_plus_1\n",
    "        f_of_x.append(f(x_t))\n",
    "    print(\"X value found: \",x_t)\n",
    "    print(\"Number of iterations before convergence: \",t)\n",
    "    plt.plot(np.arange(len(f_of_x)),f_of_x)\n",
    "    plt.show()\n",
    "\n",
    "print()\n",
    "print(\"Exercise 1 part 1\")\n",
    "print()\n",
    "# The equation from the HW\n",
    "def f(x: np.ndarray) -> np.ndarray:\n",
    "    return (x**4) + (3*(x**3)) + (10*((x-4)**2))\n",
    "\n",
    "\n",
    "# df(x)/dx\n",
    "def df_dx(x: np.ndarray) -> float:\n",
    "    return (4*(x**3)) + (9*(x**2)) + (20*(x-4))  # derivative of ax^b is bax^(b-1)\n",
    " \n",
    "    \n",
    "# make some data\n",
    "x: np.ndarray = np.arange(-100, 100+0.01, 0.01)\n",
    "y: np.ndarray = f(x)\n",
    "\n",
    "    \n",
    "main()\n",
    "\n",
    "print()\n",
    "print(\"Exercise 1 part 2\")\n",
    "print()\n",
    "# The equation from the HW\n",
    "def f(x: np.ndarray) -> np.ndarray:\n",
    "    return np.sum((x-(np.arange(x.shape[-1])+1))**2)\n",
    "\n",
    "\n",
    "# df(x)/dx\n",
    "def df_dx(x: np.ndarray) -> float:\n",
    "    return 2*(x-(np.arange(x.shape[-1])+1)) # derivative of ax^2 is 2ax\n",
    " \n",
    "    \n",
    "# make some data\n",
    "x: np.ndarray = np.arange(-100, 100+0.01, 0.01)\n",
    "y: np.ndarray = f(x)\n",
    "    \n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
