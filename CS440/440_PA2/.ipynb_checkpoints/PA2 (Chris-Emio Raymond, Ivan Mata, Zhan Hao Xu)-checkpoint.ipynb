{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_frame_smaller(frame,ratio):\n",
    "    # get size from a matrix\n",
    "    height = frame.shape[0]\n",
    "    width = frame.shape[1]\n",
    "    #resize using cv2.resize(...)\n",
    "    result = cv2.resize(frame,(int(width*ratio),int(height*ratio)))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def background_removal(frame):\n",
    "    #iterate each pixel in a frame\n",
    "    for i in range(frame.shape[0]):\n",
    "        for j in range(frame.shape[1]):\n",
    "            b,g,r = frame[i][j]\n",
    "            #for red color pixel:\n",
    "            if (r > 150 and b < 100 and g < 100):\n",
    "                #white\n",
    "                frame[i][j][0] = 255\n",
    "                frame[i][j][1] = 255\n",
    "                frame[i][j][2] = 255\n",
    "            elif (r>60 and g>40 and b>20 and max(r,g,b)-min(r,g,b)>15 and abs(r-g)>15 and r>g and r>b):\n",
    "                 #white\n",
    "                frame[i][j][0] = 255\n",
    "                frame[i][j][1] = 255\n",
    "                frame[i][j][2] = 255\n",
    "            else:\n",
    "                #black\n",
    "                frame[i][j][0] = 0\n",
    "                frame[i][j][1] = 0\n",
    "                frame[i][j][2] = 0\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def myFrameDifferencing(prev, curr):\n",
    "    \n",
    "    dst = cv2.absdiff(curr, prev)\n",
    "    dst = cv2.cvtColor(dst, cv2.COLOR_BGR2GRAY)\n",
    "    _, dst = cv2.threshold(dst, 50, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:12: RuntimeWarning: overflow encountered in ubyte_scalars\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "#You don't have to modify the code here, it simply reads the input from your camera, and run functions above to give an\n",
    "#image showing where your object is. \n",
    "\n",
    "#Access camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "#Import templates\n",
    "palmTp = cv2.imread(\"palm.png\")\n",
    "    \n",
    "thumbTp = cv2.imread(\"thumb.png\")\n",
    " \n",
    "rockTp = cv2.imread(\"fist.png\")\n",
    "\n",
    "#Initialize old frame that will be used in detecting frame differences\n",
    "ret, old_frame = cap.read()\n",
    "old_frame = make_frame_smaller(old_frame,0.2)\n",
    "\n",
    "while(True):\n",
    "    #Start reading frames from camera\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    \n",
    "    #make your frames smaller\n",
    "    frame = make_frame_smaller(frame,0.2)\n",
    "    original = frame.copy()\n",
    "    \n",
    "    #remove your back ground\n",
    "    frame = background_removal(frame)\n",
    "\n",
    "    \n",
    "    #template matching for your object\n",
    "\n",
    "    #Sets a threshold for maxVal to increase accuracy of detection\n",
    "    maxVal = 0.4\n",
    "    \n",
    "    #Label none if there no current hand gestures or motion\n",
    "    label = \"none\"\n",
    "    color = (0,0,0)\n",
    "    xleft,ytop = 10,10\n",
    "    \n",
    "    \n",
    "    #Continuosly call match template on each separate gesture template\n",
    "    resPalm = cv2.matchTemplate(frame, palmTp, cv2.TM_CCOEFF_NORMED)\n",
    "    min_valPalm, max_valPalm, min_locPalm, max_locPalm = cv2.minMaxLoc(resPalm)\n",
    "         \n",
    "    resThumb = cv2.matchTemplate(frame, thumbTp, cv2.TM_CCOEFF_NORMED)\n",
    "    min_valThumb, max_valThumb, min_locThumb, max_locThumb = cv2.minMaxLoc(resThumb)\n",
    "        \n",
    "    resRock = cv2.matchTemplate(frame, rockTp, cv2.TM_CCOEFF_NORMED)\n",
    "    min_valRock, max_valRock, min_locRock, max_locRock = cv2.minMaxLoc(resRock)\n",
    "        \n",
    "       \n",
    "    #Test agaisnt the treshhold value and updates threshold value to give more accurate gestures\n",
    "    #Label the gestures\n",
    "    #Set location of match with bounding box so it always encases it\n",
    "    if(max_valPalm > maxVal):\n",
    "        label = \"Palm\" \n",
    "        color = (255,0,0)\n",
    "        maxVal = max_valPalm\n",
    "        matchLoc = max_locPalm\n",
    "        xleft,ytop = max_locPalm\n",
    "         \n",
    "        \n",
    "    if(max_valThumb > maxVal):\n",
    "        label = \"Thumb\"\n",
    "        color = (0,0,255)\n",
    "        maxVal = max_valThumb\n",
    "        matchLoc = max_locThumb\n",
    "        xleft,ytop = max_locThumb\n",
    "\n",
    "            \n",
    "    if(max_valRock > maxVal):\n",
    "        label = \"Fist\"\n",
    "        color = (0,255,0)\n",
    "        maxVal = max_valRock\n",
    "        matchLoc = max_locRock\n",
    "        xleft,ytop = max_locRock\n",
    "\n",
    "\n",
    "    #Call checks difference from old_frame to frame\n",
    "    diff = myFrameDifferencing(old_frame, frame)\n",
    "    \n",
    "    #Detects huge difference in motion as dynamic differencing\n",
    "    nonZeros = np.count_nonzero(diff)\n",
    "    if(nonZeros >= 5000):\n",
    "        label = \"Wave\"\n",
    "        color = (0,255,255)\n",
    "    \n",
    "    #Font and color of label\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(original, label, (10,60), font, 1, color, 2, cv2.LINE_AA)\n",
    "    \n",
    "    #Initializes the bounding box\n",
    "    bottom_right = (xleft + 100, ytop + 100) #you may use the width and height of the template in here instead.\n",
    "    cv2.rectangle(original,(xleft,ytop), bottom_right, (0,255,0), 2)\n",
    "\n",
    "    \n",
    "#     print(nonZeros)\n",
    "    \n",
    "    #Different windows to show, used for testing\n",
    "    cv2.imshow(\"Background Differencing/Skin Detection\", frame)\n",
    "    cv2.imshow(\"Difference in frames\", diff)\n",
    "    cv2.imshow(\"Paper\", palmTp)\n",
    "    cv2.imshow(\"Thumb\", thumbTp)\n",
    "    cv2.imshow(\"Fist\", rockTp)\n",
    "    cv2.imshow('output',original)\n",
    "    \n",
    "    \n",
    "    #Set old_frame to current frame \n",
    "    old_frame = frame\n",
    "    \n",
    "    #press q to stop capturing frames\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
